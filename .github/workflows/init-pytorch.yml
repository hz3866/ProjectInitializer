name: Init PyTorch Project

on:
  workflow_dispatch:
    inputs:
      project_name:
        description: 'Project Name (will be used as new repository name)'
        required: true
        type: string

      python_version:
        description: 'Python Version'
        required: true
        type: choice
        options:
          - '3.10'
          - '3.11'
          - '3.12'
        default: '3.11'

      pytorch_version:
        description: 'PyTorch Version'
        required: true
        type: choice
        options:
          - '2.1'
          - '2.2'
          - '2.3'
          - '2.4'
          - '2.5'
        default: '2.5'

      repo_visibility:
        description: 'Repository Visibility'
        required: true
        type: choice
        options:
          - 'public'
          - 'private'
        default: 'public'

jobs:
  create-pytorch:
    runs-on: ubuntu-latest
    steps:
      - name: Validate project name
        run: |
          if [[ ! "${{ inputs.project_name }}" =~ ^[a-zA-Z][a-zA-Z0-9_]*$ ]]; then
            echo "::error::Invalid project name. Must start with a letter and contain only letters, numbers, and underscores."
            exit 1
          fi

      # Checkout this repo to get templates
      - name: Checkout templates
        uses: actions/checkout@v4
        with:
          path: templates-repo

      - name: Set up Python ${{ inputs.python_version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ inputs.python_version }}

      - name: Create PyTorch project
        run: |
          mkdir ${{ inputs.project_name }}
          cd ${{ inputs.project_name }}
          
          # Create directory structure
          mkdir -p src/models src/data src/utils notebooks experiments data/raw data/processed checkpoints
          
          # Create requirements files
          cat > requirements.txt << 'EOF'
          torch~=${{ inputs.pytorch_version }}
          torchvision
          numpy>=1.24.0
          pandas>=2.0.0
          scikit-learn>=1.3.0
          matplotlib>=3.7.0
          seaborn>=0.12.0
          tqdm>=4.65.0
          pyyaml>=6.0
          tensorboard>=2.14.0
          python-dotenv>=1.0.0
          EOF
          
          cat > requirements-dev.txt << 'EOF'
          pytest>=8.0.0
          ruff>=0.3.0
          jupyter>=1.0.0
          ipykernel>=6.25.0
          EOF
          
          # Create Python source files
          touch src/__init__.py
          touch src/models/__init__.py
          touch src/data/__init__.py
          touch src/utils/__init__.py
          
          cat > src/models/base.py << 'PYEOF'
          import torch
          import torch.nn as nn


          class BaseModel(nn.Module):
              """Base model class with common utilities."""
              
              def __init__(self):
                  super().__init__()
              
              def count_parameters(self) -> int:
                  """Count trainable parameters."""
                  return sum(p.numel() for p in self.parameters() if p.requires_grad)
              
              def save(self, path: str) -> None:
                  """Save model checkpoint."""
                  torch.save({'model_state_dict': self.state_dict()}, path)
              
              def load(self, path: str, device: str = 'cpu') -> None:
                  """Load model checkpoint."""
                  checkpoint = torch.load(path, map_location=device)
                  self.load_state_dict(checkpoint['model_state_dict'])


          class SimpleMLP(BaseModel):
              """Simple MLP example model."""
              
              def __init__(self, input_dim: int, hidden_dim: int, output_dim: int):
                  super().__init__()
                  self.layers = nn.Sequential(
                      nn.Linear(input_dim, hidden_dim),
                      nn.ReLU(),
                      nn.Dropout(0.2),
                      nn.Linear(hidden_dim, hidden_dim),
                      nn.ReLU(),
                      nn.Dropout(0.2),
                      nn.Linear(hidden_dim, output_dim),
                  )
              
              def forward(self, x: torch.Tensor) -> torch.Tensor:
                  return self.layers(x)
          PYEOF
          
          cat > src/data/dataset.py << 'PYEOF'
          import torch
          from torch.utils.data import Dataset, DataLoader
          from typing import Tuple, Optional
          import numpy as np


          class BaseDataset(Dataset):
              """Base dataset class."""
              
              def __init__(self, X: np.ndarray, y: np.ndarray):
                  self.X = torch.FloatTensor(X)
                  self.y = torch.LongTensor(y)
              
              def __len__(self) -> int:
                  return len(self.X)
              
              def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
                  return self.X[idx], self.y[idx]


          def create_dataloaders(
              train_X: np.ndarray,
              train_y: np.ndarray,
              val_X: Optional[np.ndarray] = None,
              val_y: Optional[np.ndarray] = None,
              batch_size: int = 32,
              num_workers: int = 0,
          ) -> Tuple[DataLoader, Optional[DataLoader]]:
              """Create train and validation dataloaders."""
              train_dataset = BaseDataset(train_X, train_y)
              train_loader = DataLoader(
                  train_dataset,
                  batch_size=batch_size,
                  shuffle=True,
                  num_workers=num_workers,
              )
              
              val_loader = None
              if val_X is not None and val_y is not None:
                  val_dataset = BaseDataset(val_X, val_y)
                  val_loader = DataLoader(
                      val_dataset,
                      batch_size=batch_size,
                      shuffle=False,
                      num_workers=num_workers,
                  )
              
              return train_loader, val_loader
          PYEOF
          
          cat > src/utils/config.py << 'PYEOF'
          from dataclasses import dataclass
          import yaml


          @dataclass
          class Config:
              """Training configuration."""
              model_name: str = "SimpleMLP"
              input_dim: int = 784
              hidden_dim: int = 256
              output_dim: int = 10
              batch_size: int = 32
              learning_rate: float = 1e-3
              epochs: int = 10
              device: str = "cpu"
              seed: int = 42
              num_workers: int = 0
              checkpoint_dir: str = "checkpoints"
              log_dir: str = "experiments/runs"
              
              @classmethod
              def from_yaml(cls, path: str) -> "Config":
                  """Load config from YAML file."""
                  with open(path, 'r') as f:
                      data = yaml.safe_load(f)
                  return cls(**data)
              
              def to_yaml(self, path: str) -> None:
                  """Save config to YAML file."""
                  with open(path, 'w') as f:
                      yaml.dump(self.__dict__, f, default_flow_style=False)
          PYEOF
          
          cat > train.py << 'PYEOF'
          """Main training script."""
          import argparse
          import torch
          import torch.nn as nn
          from sklearn.datasets import make_classification
          from sklearn.model_selection import train_test_split

          from src.models.base import SimpleMLP
          from src.data.dataset import create_dataloaders
          from src.utils.config import Config


          def main():
              parser = argparse.ArgumentParser(description='Train model')
              parser.add_argument('--config', type=str, default=None, help='Config file path')
              parser.add_argument('--epochs', type=int, default=10, help='Number of epochs')
              parser.add_argument('--batch-size', type=int, default=32, help='Batch size')
              parser.add_argument('--lr', type=float, default=1e-3, help='Learning rate')
              args = parser.parse_args()
              
              if args.config:
                  config = Config.from_yaml(args.config)
              else:
                  config = Config(
                      epochs=args.epochs,
                      batch_size=args.batch_size,
                      learning_rate=args.lr,
                  )
              
              device = 'cuda' if torch.cuda.is_available() else 'cpu'
              print(f"Using device: {device}")
              
              # Create dummy data for demonstration
              X, y = make_classification(
                  n_samples=1000,
                  n_features=config.input_dim,
                  n_informative=50,
                  n_classes=config.output_dim,
                  random_state=config.seed,
              )
              
              X_train, X_val, y_train, y_val = train_test_split(
                  X, y, test_size=0.2, random_state=config.seed
              )
              
              train_loader, val_loader = create_dataloaders(
                  X_train, y_train, X_val, y_val,
                  batch_size=config.batch_size,
              )
              
              model = SimpleMLP(
                  input_dim=config.input_dim,
                  hidden_dim=config.hidden_dim,
                  output_dim=config.output_dim,
              ).to(device)
              
              print(f"Model parameters: {model.count_parameters():,}")
              
              optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)
              criterion = nn.CrossEntropyLoss()
              
              for epoch in range(config.epochs):
                  model.train()
                  total_loss = 0
                  for batch_X, batch_y in train_loader:
                      batch_X, batch_y = batch_X.to(device), batch_y.to(device)
                      optimizer.zero_grad()
                      outputs = model(batch_X)
                      loss = criterion(outputs, batch_y)
                      loss.backward()
                      optimizer.step()
                      total_loss += loss.item()
                  
                  avg_loss = total_loss / len(train_loader)
                  print(f"Epoch {epoch+1}/{config.epochs}, Loss: {avg_loss:.4f}")
              
              print("\nTraining complete!")


          if __name__ == '__main__':
              main()
          PYEOF
          
          cat > experiments/config.yaml << 'EOF'
          model_name: SimpleMLP
          input_dim: 784
          hidden_dim: 256
          output_dim: 10
          batch_size: 32
          learning_rate: 0.001
          epochs: 10
          device: cpu
          seed: 42
          num_workers: 0
          EOF
          
          # Create .gitkeep files
          touch data/raw/.gitkeep
          touch data/processed/.gitkeep
          touch checkpoints/.gitkeep
          
          # Create notebook
          cat > notebooks/01_exploration.ipynb << 'EOF'
          {
           "cells": [
            {
             "cell_type": "markdown",
             "metadata": {},
             "source": ["# Data Exploration\n", "\n", "This notebook is for exploring and understanding the dataset."]
            },
            {
             "cell_type": "code",
             "execution_count": null,
             "metadata": {},
             "outputs": [],
             "source": ["import torch\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "print(f\"PyTorch version: {torch.__version__}\")\n", "print(f\"CUDA available: {torch.cuda.is_available()}\")"]
            },
            {
             "cell_type": "code",
             "execution_count": null,
             "metadata": {},
             "outputs": [],
             "source": ["# Add your exploration code here"]
            }
           ],
           "metadata": {
            "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
            "language_info": {"name": "python", "version": "${{ inputs.python_version }}"}
           },
           "nbformat": 4,
           "nbformat_minor": 4
          }
          EOF
          
          # Create release.yaml
          cat > release.yaml << 'EOF'
          version: "0.1.0"
          EOF

      - name: Copy template files
        run: |
          cd ${{ inputs.project_name }}
          
          # Copy shared files (CI/CD workflow)
          mkdir -p .github/workflows
          cp ../templates-repo/templates/shared/.github/workflows/docker-build-push.yml .github/workflows/
          
          # Copy PyTorch-specific files
          cp ../templates-repo/templates/pytorch/.gitignore .
          
          # Process Dockerfile template
          sed -e 's/{{PYTHON_VERSION}}/${{ inputs.python_version }}/g' \
              ../templates-repo/templates/pytorch/Dockerfile.template > Dockerfile

      - name: Create README
        run: |
          cd ${{ inputs.project_name }}
          cat > README.md << 'EOF'
          # ${{ inputs.project_name }}
          
          A PyTorch machine learning project.
          
          ## Tech Stack
          
          - Python: ${{ inputs.python_version }}
          - PyTorch: ${{ inputs.pytorch_version }}
          
          ## Quick Start
          
          ```bash
          # Create virtual environment
          python -m venv venv
          source venv/bin/activate  # On Windows: venv\Scripts\activate
          
          # Install dependencies
          pip install -r requirements.txt
          pip install -r requirements-dev.txt  # For development
          
          # Run training
          python train.py --epochs 10 --batch-size 32
          
          # Or with config file
          python train.py --config experiments/config.yaml
          
          # Monitor with TensorBoard
          tensorboard --logdir experiments/runs
          ```
          
          ## Docker
          
          ```bash
          # Build image
          docker build -t ${{ inputs.project_name }}:latest .
          
          # Run training in container
          docker run ${{ inputs.project_name }}:latest
          
          # Run with GPU support
          docker run --gpus all ${{ inputs.project_name }}:latest
          ```
          
          ## CI/CD
          
          This project includes a GitHub Action workflow for automatic Docker image builds:
          - Triggers on push to main/master branch
          - Can be manually triggered via workflow_dispatch
          - Pushes images to DockerHub
          - Runs Trivy security scan
          
          ### Required GitHub Secrets
          
          | Secret | Description |
          |--------|-------------|
          | `DOCKERHUB_USERNAME` | Your DockerHub username |
          | `DOCKERHUB_TOKEN` | Your DockerHub access token |
          
          ## Project Structure
          
          ```
          ${{ inputs.project_name }}/
          â”œâ”€â”€ src/
          â”‚   â”œâ”€â”€ models/          # Model definitions
          â”‚   â”œâ”€â”€ data/            # Data loading utilities
          â”‚   â””â”€â”€ utils/           # Training utilities
          â”œâ”€â”€ notebooks/           # Jupyter notebooks
          â”œâ”€â”€ experiments/         # Experiment configs and logs
          â”œâ”€â”€ data/
          â”‚   â”œâ”€â”€ raw/
          â”‚   â””â”€â”€ processed/
          â”œâ”€â”€ checkpoints/         # Model checkpoints
          â”œâ”€â”€ .github/workflows/
          â”‚   â””â”€â”€ docker-build-push.yml
          â”œâ”€â”€ Dockerfile
          â”œâ”€â”€ train.py
          â””â”€â”€ README.md
          ```
          EOF

      - name: Create repo and push
        env:
          GH_TOKEN: ${{ secrets.PAT_TOKEN }}
        run: |
          cd ${{ inputs.project_name }}
          git config --global user.name "${{ github.actor }}"
          git config --global user.email "${{ github.actor }}@users.noreply.github.com"
          git init
          git add .
          git commit -m "Initial PyTorch ${{ inputs.pytorch_version }} ML project"
          gh repo create ${{ inputs.project_name }} --${{ inputs.repo_visibility }} --source . --push
          echo "âœ… Repo created: https://github.com/${{ github.repository_owner }}/${{ inputs.project_name }}"

      - name: Create poc branch
        env:
          GH_TOKEN: ${{ secrets.PAT_TOKEN }}
        run: |
          cd ${{ inputs.project_name }}
          git remote set-url origin https://x-access-token:${GH_TOKEN}@github.com/${{ github.repository_owner }}/${{ inputs.project_name }}.git
          git checkout -b poc
          git push -u origin poc
          git checkout main
          echo "âœ… Branch 'poc' created"

      - name: Set secrets for new repo
        env:
          GH_TOKEN: ${{ secrets.PAT_TOKEN }}
        run: |
          REPO="${{ github.repository_owner }}/${{ inputs.project_name }}"
          echo "ðŸ” Setting secrets for ${REPO}..."
          echo "${{ secrets.DOCKERHUB_USERNAME }}" | gh secret set DOCKERHUB_USERNAME --repo ${REPO}
          echo "${{ secrets.DOCKERHUB_TOKEN }}" | gh secret set DOCKERHUB_TOKEN --repo ${REPO}
          echo "âœ… Secrets configured"
