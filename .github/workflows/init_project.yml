name: Init Project

on:
  workflow_dispatch:
    inputs:
      project_type:
        description: 'Project Type'
        required: true
        type: choice
        options:
          - 'django'
          - 'fastapi'
          - 'pytorch'
          - 'jupyter'
          - 'react'
          - 'vue'

      project_name:
        description: 'Project Name (will be used as new repository name)'
        required: true
        type: string

      # ===== Python Options =====
      python_version:
        description: 'Python Version (for django/fastapi/pytorch/jupyter)'
        required: false
        type: choice
        options:
          - '3.10'
          - '3.11'
          - '3.12'
        default: '3.11'

      django_version:
        description: 'Django Version (only for django)'
        required: false
        type: choice
        options:
          - '4.2'
          - '5.0'
          - '5.1'
        default: '5.0'

      fastapi_version:
        description: 'FastAPI Version (only for fastapi)'
        required: false
        type: choice
        options:
          - '0.109'
          - '0.110'
          - '0.111'
          - '0.115'
        default: '0.115'

      pytorch_version:
        description: 'PyTorch Version (only for pytorch)'
        required: false
        type: choice
        options:
          - '2.1'
          - '2.2'
          - '2.3'
          - '2.4'
          - '2.5'
        default: '2.5'

      # ===== Node.js Options =====
      node_version:
        description: 'Node.js Version (for react/vue)'
        required: false
        type: choice
        options:
          - '18'
          - '20'
          - '22'
        default: '20'

      react_version:
        description: 'React Version (only for react)'
        required: false
        type: choice
        options:
          - '18'
          - '19'
        default: '19'

      vue_version:
        description: 'Vue Version (only for vue)'
        required: false
        type: choice
        options:
          - '3.4'
          - '3.5'
        default: '3.5'

      # ===== Common Options =====
      repo_visibility:
        description: 'Repository Visibility'
        required: false
        type: choice
        options:
          - 'public'
          - 'private'
        default: 'public'

jobs:
  # ============================================================
  # Validation Job
  # ============================================================
  validate:
    runs-on: ubuntu-latest
    steps:
      - name: Validate project name
        run: |
          if [[ ! "${{ inputs.project_name }}" =~ ^[a-zA-Z][a-zA-Z0-9_-]*$ ]]; then
            echo "::error::Invalid project name. Must start with a letter and contain only letters, numbers, hyphens, and underscores."
            exit 1
          fi

      - name: Validate input combinations
        run: |
          PROJECT_TYPE="${{ inputs.project_type }}"
          
          echo "Project Type: $PROJECT_TYPE"
          echo "Validating input combinations..."
          
          # Python projects: django, fastapi, pytorch, jupyter
          # Node projects: react, vue
          
          case "$PROJECT_TYPE" in
            django|fastapi|pytorch|jupyter)
              echo "✓ Python project detected"
              ;;
            react|vue)
              echo "✓ Node.js project detected"
              ;;
            *)
              echo "::error::Unknown project type: $PROJECT_TYPE"
              exit 1
              ;;
          esac
          
          echo "✓ Validation passed"

  # ============================================================
  # Django Project
  # ============================================================
  create-django:
    needs: validate
    if: inputs.project_type == 'django'
    runs-on: ubuntu-latest
    steps:
      - name: Set up Python ${{ inputs.python_version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ inputs.python_version }}

      - name: Install Django
        run: |
          pip install --upgrade pip
          pip install Django~=${{ inputs.django_version }}.0

      - name: Create Django project
        run: |
          django-admin startproject ${{ inputs.project_name }}
          cd ${{ inputs.project_name }}
          
          cat > requirements.txt << 'EOF'
          Django~=${{ inputs.django_version }}.0
          python-dotenv>=1.0.0
          EOF
          
          cat > .gitignore << 'EOF'
          # Python
          __pycache__/
          *.py[cod]
          *$py.class
          *.so
          .Python
          build/
          develop-eggs/
          dist/
          downloads/
          eggs/
          .eggs/
          lib/
          lib64/
          parts/
          sdist/
          var/
          wheels/
          *.egg-info/
          .installed.cfg
          *.egg
          
          # Virtual Environment
          venv/
          .venv/
          ENV/
          env/
          
          # Django
          *.log
          db.sqlite3
          media/
          staticfiles/
          
          # Environment
          .env
          .env.local
          
          # IDE
          .idea/
          .vscode/
          *.swp
          *.swo
          
          # OS
          .DS_Store
          Thumbs.db
          EOF
          
          cat > .env.example << 'EOF'
          DEBUG=True
          SECRET_KEY=your-secret-key-here
          ALLOWED_HOSTS=localhost,127.0.0.1
          EOF
          
          cat > README.md << 'EOF'
          # ${{ inputs.project_name }}
          
          A Django project.
          
          ## Tech Stack
          
          - Python: ${{ inputs.python_version }}
          - Django: ${{ inputs.django_version }}
          
          ## Quick Start
          
          ```bash
          # Create virtual environment
          python -m venv venv
          source venv/bin/activate  # On Windows: venv\Scripts\activate
          
          # Install dependencies
          pip install -r requirements.txt
          
          # Setup environment
          cp .env.example .env
          
          # Run migrations
          python manage.py migrate
          
          # Create superuser (optional)
          python manage.py createsuperuser
          
          # Run development server
          python manage.py runserver
          ```
          
          ## Project Structure
          
          ```
          ${{ inputs.project_name }}/
          ├── ${{ inputs.project_name }}/
          │   ├── __init__.py
          │   ├── settings.py
          │   ├── urls.py
          │   ├── asgi.py
          │   └── wsgi.py
          ├── manage.py
          ├── requirements.txt
          ├── .env.example
          └── README.md
          ```
          EOF

      - name: Create repo and push
        env:
          GH_TOKEN: ${{ secrets.PAT_TOKEN }}
        run: |
          cd ${{ inputs.project_name }}
          git config --global user.name "${{ github.actor }}"
          git config --global user.email "${{ github.actor }}@users.noreply.github.com"
          git init
          git add .
          git commit -m "Initial Django ${{ inputs.django_version }} project"
          gh repo create ${{ inputs.project_name }} --${{ inputs.repo_visibility }} --source . --push
          echo "✅ Done: https://github.com/${{ github.repository_owner }}/${{ inputs.project_name }}"

  # ============================================================
  # FastAPI Project
  # ============================================================
  create-fastapi:
    needs: validate
    if: inputs.project_type == 'fastapi'
    runs-on: ubuntu-latest
    steps:
      - name: Set up Python ${{ inputs.python_version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ inputs.python_version }}

      - name: Create FastAPI project
        run: |
          mkdir ${{ inputs.project_name }}
          cd ${{ inputs.project_name }}
          
          # Create project structure
          mkdir -p app/api app/core app/models app/schemas tests
          
          cat > requirements.txt << 'EOF'
          fastapi~=${{ inputs.fastapi_version }}
          uvicorn[standard]>=0.27.0
          pydantic>=2.0.0
          pydantic-settings>=2.0.0
          python-dotenv>=1.0.0
          EOF
          
          cat > requirements-dev.txt << 'EOF'
          pytest>=8.0.0
          pytest-asyncio>=0.23.0
          httpx>=0.27.0
          ruff>=0.3.0
          EOF
          
          cat > app/__init__.py << 'EOF'
          EOF
          
          cat > app/main.py << 'EOF'
          from fastapi import FastAPI
          from app.core.config import settings
          
          app = FastAPI(
              title=settings.APP_NAME,
              version=settings.APP_VERSION,
              description="A FastAPI project",
          )
          
          
          @app.get("/")
          async def root():
              return {"message": "Hello World", "app": settings.APP_NAME}
          
          
          @app.get("/health")
          async def health_check():
              return {"status": "healthy"}
          EOF
          
          cat > app/core/__init__.py << 'EOF'
          EOF
          
          cat > app/core/config.py << 'EOF'
          from pydantic_settings import BaseSettings
          
          
          class Settings(BaseSettings):
              APP_NAME: str = "${{ inputs.project_name }}"
              APP_VERSION: str = "0.1.0"
              DEBUG: bool = True
          
              class Config:
                  env_file = ".env"
          
          
          settings = Settings()
          EOF
          
          cat > app/api/__init__.py << 'EOF'
          EOF
          
          cat > app/models/__init__.py << 'EOF'
          EOF
          
          cat > app/schemas/__init__.py << 'EOF'
          EOF
          
          cat > tests/__init__.py << 'EOF'
          EOF
          
          cat > tests/test_main.py << 'EOF'
          import pytest
          from httpx import AsyncClient, ASGITransport
          from app.main import app
          
          
          @pytest.mark.asyncio
          async def test_root():
              async with AsyncClient(transport=ASGITransport(app=app), base_url="http://test") as client:
                  response = await client.get("/")
              assert response.status_code == 200
              assert "message" in response.json()
          
          
          @pytest.mark.asyncio
          async def test_health():
              async with AsyncClient(transport=ASGITransport(app=app), base_url="http://test") as client:
                  response = await client.get("/health")
              assert response.status_code == 200
              assert response.json()["status"] == "healthy"
          EOF
          
          cat > pytest.ini << 'EOF'
          [pytest]
          asyncio_mode = auto
          testpaths = tests
          EOF
          
          cat > .gitignore << 'EOF'
          # Python
          __pycache__/
          *.py[cod]
          *$py.class
          *.so
          .Python
          build/
          develop-eggs/
          dist/
          downloads/
          eggs/
          .eggs/
          lib/
          lib64/
          parts/
          sdist/
          var/
          wheels/
          *.egg-info/
          .installed.cfg
          *.egg
          
          # Virtual Environment
          venv/
          .venv/
          ENV/
          env/
          
          # Environment
          .env
          .env.local
          
          # IDE
          .idea/
          .vscode/
          *.swp
          *.swo
          
          # OS
          .DS_Store
          Thumbs.db
          
          # Testing
          .pytest_cache/
          .coverage
          htmlcov/
          
          # Ruff
          .ruff_cache/
          EOF
          
          cat > .env.example << 'EOF'
          APP_NAME=${{ inputs.project_name }}
          APP_VERSION=0.1.0
          DEBUG=True
          EOF
          
          cat > README.md << 'EOF'
          # ${{ inputs.project_name }}
          
          A FastAPI project.
          
          ## Tech Stack
          
          - Python: ${{ inputs.python_version }}
          - FastAPI: ${{ inputs.fastapi_version }}
          
          ## Quick Start
          
          ```bash
          # Create virtual environment
          python -m venv venv
          source venv/bin/activate  # On Windows: venv\Scripts\activate
          
          # Install dependencies
          pip install -r requirements.txt
          pip install -r requirements-dev.txt  # For development
          
          # Setup environment
          cp .env.example .env
          
          # Run development server
          uvicorn app.main:app --reload
          
          # Run tests
          pytest
          ```
          
          ## API Documentation
          
          Once the server is running, visit:
          - Swagger UI: http://localhost:8000/docs
          - ReDoc: http://localhost:8000/redoc
          
          ## Project Structure
          
          ```
          ${{ inputs.project_name }}/
          ├── app/
          │   ├── __init__.py
          │   ├── main.py
          │   ├── api/
          │   ├── core/
          │   │   └── config.py
          │   ├── models/
          │   └── schemas/
          ├── tests/
          │   └── test_main.py
          ├── requirements.txt
          ├── requirements-dev.txt
          ├── pytest.ini
          ├── .env.example
          └── README.md
          ```
          EOF

      - name: Create repo and push
        env:
          GH_TOKEN: ${{ secrets.PAT_TOKEN }}
        run: |
          cd ${{ inputs.project_name }}
          git config --global user.name "${{ github.actor }}"
          git config --global user.email "${{ github.actor }}@users.noreply.github.com"
          git init
          git add .
          git commit -m "Initial FastAPI ${{ inputs.fastapi_version }} project"
          gh repo create ${{ inputs.project_name }} --${{ inputs.repo_visibility }} --source . --push
          echo "✅ Done: https://github.com/${{ github.repository_owner }}/${{ inputs.project_name }}"

  # ============================================================
  # PyTorch ML Project
  # ============================================================
  create-pytorch:
    needs: validate
    if: inputs.project_type == 'pytorch'
    runs-on: ubuntu-latest
    steps:
      - name: Set up Python ${{ inputs.python_version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ inputs.python_version }}

      - name: Create PyTorch project
        run: |
          mkdir ${{ inputs.project_name }}
          cd ${{ inputs.project_name }}
          
          # Create project structure
          mkdir -p src/models src/data src/utils notebooks experiments data/raw data/processed checkpoints
          
          cat > requirements.txt << 'EOF'
          torch~=${{ inputs.pytorch_version }}
          torchvision
          numpy>=1.24.0
          pandas>=2.0.0
          scikit-learn>=1.3.0
          matplotlib>=3.7.0
          seaborn>=0.12.0
          tqdm>=4.65.0
          pyyaml>=6.0
          tensorboard>=2.14.0
          python-dotenv>=1.0.0
          EOF
          
          cat > requirements-dev.txt << 'EOF'
          pytest>=8.0.0
          ruff>=0.3.0
          jupyter>=1.0.0
          ipykernel>=6.25.0
          EOF
          
          cat > src/__init__.py << 'EOF'
          EOF
          
          cat > src/models/__init__.py << 'EOF'
          EOF
          
          cat > src/models/base.py << 'EOF'
          import torch
          import torch.nn as nn
          
          
          class BaseModel(nn.Module):
              """Base model class with common utilities."""
              
              def __init__(self):
                  super().__init__()
              
              def count_parameters(self) -> int:
                  """Count trainable parameters."""
                  return sum(p.numel() for p in self.parameters() if p.requires_grad)
              
              def save(self, path: str) -> None:
                  """Save model checkpoint."""
                  torch.save({
                      'model_state_dict': self.state_dict(),
                  }, path)
              
              def load(self, path: str, device: str = 'cpu') -> None:
                  """Load model checkpoint."""
                  checkpoint = torch.load(path, map_location=device)
                  self.load_state_dict(checkpoint['model_state_dict'])
          
          
          class SimpleMLP(BaseModel):
              """Simple MLP example model."""
              
              def __init__(self, input_dim: int, hidden_dim: int, output_dim: int):
                  super().__init__()
                  self.layers = nn.Sequential(
                      nn.Linear(input_dim, hidden_dim),
                      nn.ReLU(),
                      nn.Dropout(0.2),
                      nn.Linear(hidden_dim, hidden_dim),
                      nn.ReLU(),
                      nn.Dropout(0.2),
                      nn.Linear(hidden_dim, output_dim),
                  )
              
              def forward(self, x: torch.Tensor) -> torch.Tensor:
                  return self.layers(x)
          EOF
          
          cat > src/data/__init__.py << 'EOF'
          EOF
          
          cat > src/data/dataset.py << 'EOF'
          import torch
          from torch.utils.data import Dataset, DataLoader
          from typing import Tuple, Optional
          import numpy as np
          
          
          class BaseDataset(Dataset):
              """Base dataset class."""
              
              def __init__(self, X: np.ndarray, y: np.ndarray):
                  self.X = torch.FloatTensor(X)
                  self.y = torch.LongTensor(y)
              
              def __len__(self) -> int:
                  return len(self.X)
              
              def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
                  return self.X[idx], self.y[idx]
          
          
          def create_dataloaders(
              train_X: np.ndarray,
              train_y: np.ndarray,
              val_X: Optional[np.ndarray] = None,
              val_y: Optional[np.ndarray] = None,
              batch_size: int = 32,
              num_workers: int = 0,
          ) -> Tuple[DataLoader, Optional[DataLoader]]:
              """Create train and validation dataloaders."""
              
              train_dataset = BaseDataset(train_X, train_y)
              train_loader = DataLoader(
                  train_dataset,
                  batch_size=batch_size,
                  shuffle=True,
                  num_workers=num_workers,
              )
              
              val_loader = None
              if val_X is not None and val_y is not None:
                  val_dataset = BaseDataset(val_X, val_y)
                  val_loader = DataLoader(
                      val_dataset,
                      batch_size=batch_size,
                      shuffle=False,
                      num_workers=num_workers,
                  )
              
              return train_loader, val_loader
          EOF
          
          cat > src/utils/__init__.py << 'EOF'
          EOF
          
          cat > src/utils/trainer.py << 'EOF'
          import torch
          import torch.nn as nn
          from torch.utils.data import DataLoader
          from torch.utils.tensorboard import SummaryWriter
          from typing import Optional, Dict
          from tqdm import tqdm
          import os
          
          
          class Trainer:
              """Model trainer with logging and checkpointing."""
              
              def __init__(
                  self,
                  model: nn.Module,
                  optimizer: torch.optim.Optimizer,
                  criterion: nn.Module,
                  device: str = 'cpu',
                  checkpoint_dir: str = 'checkpoints',
                  log_dir: str = 'experiments/runs',
              ):
                  self.model = model.to(device)
                  self.optimizer = optimizer
                  self.criterion = criterion
                  self.device = device
                  self.checkpoint_dir = checkpoint_dir
                  self.writer = SummaryWriter(log_dir)
                  
                  os.makedirs(checkpoint_dir, exist_ok=True)
              
              def train_epoch(self, train_loader: DataLoader) -> float:
                  """Train for one epoch."""
                  self.model.train()
                  total_loss = 0.0
                  
                  for batch_X, batch_y in tqdm(train_loader, desc="Training"):
                      batch_X = batch_X.to(self.device)
                      batch_y = batch_y.to(self.device)
                      
                      self.optimizer.zero_grad()
                      outputs = self.model(batch_X)
                      loss = self.criterion(outputs, batch_y)
                      loss.backward()
                      self.optimizer.step()
                      
                      total_loss += loss.item()
                  
                  return total_loss / len(train_loader)
              
              @torch.no_grad()
              def evaluate(self, val_loader: DataLoader) -> Dict[str, float]:
                  """Evaluate model."""
                  self.model.eval()
                  total_loss = 0.0
                  correct = 0
                  total = 0
                  
                  for batch_X, batch_y in val_loader:
                      batch_X = batch_X.to(self.device)
                      batch_y = batch_y.to(self.device)
                      
                      outputs = self.model(batch_X)
                      loss = self.criterion(outputs, batch_y)
                      total_loss += loss.item()
                      
                      _, predicted = outputs.max(1)
                      total += batch_y.size(0)
                      correct += predicted.eq(batch_y).sum().item()
                  
                  return {
                      'loss': total_loss / len(val_loader),
                      'accuracy': correct / total,
                  }
              
              def fit(
                  self,
                  train_loader: DataLoader,
                  val_loader: Optional[DataLoader] = None,
                  epochs: int = 10,
              ) -> None:
                  """Full training loop."""
                  best_val_loss = float('inf')
                  
                  for epoch in range(epochs):
                      print(f"\nEpoch {epoch + 1}/{epochs}")
                      
                      train_loss = self.train_epoch(train_loader)
                      self.writer.add_scalar('Loss/train', train_loss, epoch)
                      print(f"Train Loss: {train_loss:.4f}")
                      
                      if val_loader:
                          metrics = self.evaluate(val_loader)
                          self.writer.add_scalar('Loss/val', metrics['loss'], epoch)
                          self.writer.add_scalar('Accuracy/val', metrics['accuracy'], epoch)
                          print(f"Val Loss: {metrics['loss']:.4f}, Val Acc: {metrics['accuracy']:.4f}")
                          
                          if metrics['loss'] < best_val_loss:
                              best_val_loss = metrics['loss']
                              self.save_checkpoint(f'best_model.pt')
                      
                      self.save_checkpoint(f'epoch_{epoch + 1}.pt')
                  
                  self.writer.close()
              
              def save_checkpoint(self, filename: str) -> None:
                  """Save checkpoint."""
                  path = os.path.join(self.checkpoint_dir, filename)
                  torch.save({
                      'model_state_dict': self.model.state_dict(),
                      'optimizer_state_dict': self.optimizer.state_dict(),
                  }, path)
          EOF
          
          cat > src/utils/config.py << 'EOF'
          import yaml
          from dataclasses import dataclass
          from typing import Optional
          
          
          @dataclass
          class Config:
              """Training configuration."""
              # Model
              model_name: str = "SimpleMLP"
              input_dim: int = 784
              hidden_dim: int = 256
              output_dim: int = 10
              
              # Training
              batch_size: int = 32
              learning_rate: float = 1e-3
              epochs: int = 10
              
              # System
              device: str = "cpu"
              seed: int = 42
              num_workers: int = 0
              
              @classmethod
              def from_yaml(cls, path: str) -> "Config":
                  with open(path, 'r') as f:
                      config_dict = yaml.safe_load(f)
                  return cls(**config_dict)
              
              def to_yaml(self, path: str) -> None:
                  with open(path, 'w') as f:
                      yaml.dump(self.__dict__, f, default_flow_style=False)
          EOF
          
          cat > train.py << 'EOF'
          """Main training script."""
          import argparse
          import torch
          import torch.nn as nn
          from sklearn.datasets import make_classification
          from sklearn.model_selection import train_test_split
          
          from src.models.base import SimpleMLP
          from src.data.dataset import create_dataloaders
          from src.utils.trainer import Trainer
          from src.utils.config import Config
          
          
          def main():
              parser = argparse.ArgumentParser(description='Train model')
              parser.add_argument('--config', type=str, default=None, help='Config file path')
              parser.add_argument('--epochs', type=int, default=10, help='Number of epochs')
              parser.add_argument('--batch-size', type=int, default=32, help='Batch size')
              parser.add_argument('--lr', type=float, default=1e-3, help='Learning rate')
              args = parser.parse_args()
              
              # Load config
              if args.config:
                  config = Config.from_yaml(args.config)
              else:
                  config = Config(
                      epochs=args.epochs,
                      batch_size=args.batch_size,
                      learning_rate=args.lr,
                  )
              
              # Set device
              device = 'cuda' if torch.cuda.is_available() else 'cpu'
              print(f"Using device: {device}")
              
              # Create dummy data for demonstration
              X, y = make_classification(
                  n_samples=1000,
                  n_features=config.input_dim,
                  n_informative=50,
                  n_classes=config.output_dim,
                  random_state=config.seed,
              )
              
              X_train, X_val, y_train, y_val = train_test_split(
                  X, y, test_size=0.2, random_state=config.seed
              )
              
              # Create dataloaders
              train_loader, val_loader = create_dataloaders(
                  X_train, y_train, X_val, y_val,
                  batch_size=config.batch_size,
              )
              
              # Create model
              model = SimpleMLP(
                  input_dim=config.input_dim,
                  hidden_dim=config.hidden_dim,
                  output_dim=config.output_dim,
              )
              print(f"Model parameters: {model.count_parameters():,}")
              
              # Setup training
              optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)
              criterion = nn.CrossEntropyLoss()
              
              # Train
              trainer = Trainer(
                  model=model,
                  optimizer=optimizer,
                  criterion=criterion,
                  device=device,
              )
              
              trainer.fit(train_loader, val_loader, epochs=config.epochs)
              print("\nTraining complete!")
          
          
          if __name__ == '__main__':
              main()
          EOF
          
          cat > experiments/config.yaml << 'EOF'
          # Model configuration
          model_name: SimpleMLP
          input_dim: 784
          hidden_dim: 256
          output_dim: 10
          
          # Training configuration
          batch_size: 32
          learning_rate: 0.001
          epochs: 10
          
          # System configuration
          device: cpu
          seed: 42
          num_workers: 0
          EOF
          
          # Create placeholder files
          touch data/raw/.gitkeep
          touch data/processed/.gitkeep
          touch checkpoints/.gitkeep
          
          cat > notebooks/01_exploration.ipynb << 'EOF'
          {
           "cells": [
            {
             "cell_type": "markdown",
             "metadata": {},
             "source": [
              "# Data Exploration\n",
              "\n",
              "This notebook is for exploring and understanding the dataset."
             ]
            },
            {
             "cell_type": "code",
             "execution_count": null,
             "metadata": {},
             "outputs": [],
             "source": [
              "import torch\n",
              "import numpy as np\n",
              "import pandas as pd\n",
              "import matplotlib.pyplot as plt\n",
              "import seaborn as sns\n",
              "\n",
              "print(f\"PyTorch version: {torch.__version__}\")\n",
              "print(f\"CUDA available: {torch.cuda.is_available()}\")"
             ]
            },
            {
             "cell_type": "code",
             "execution_count": null,
             "metadata": {},
             "outputs": [],
             "source": [
              "# Add your exploration code here"
             ]
            }
           ],
           "metadata": {
            "kernelspec": {
             "display_name": "Python 3",
             "language": "python",
             "name": "python3"
            },
            "language_info": {
             "name": "python",
             "version": "${{ inputs.python_version }}"
            }
           },
           "nbformat": 4,
           "nbformat_minor": 4
          }
          EOF
          
          cat > .gitignore << 'EOF'
          # Python
          __pycache__/
          *.py[cod]
          *$py.class
          *.so
          .Python
          build/
          develop-eggs/
          dist/
          downloads/
          eggs/
          .eggs/
          lib/
          lib64/
          parts/
          sdist/
          var/
          wheels/
          *.egg-info/
          .installed.cfg
          *.egg
          
          # Virtual Environment
          venv/
          .venv/
          ENV/
          env/
          
          # Jupyter
          .ipynb_checkpoints/
          *.ipynb_checkpoints
          
          # Data
          data/raw/*
          data/processed/*
          !data/raw/.gitkeep
          !data/processed/.gitkeep
          
          # Model checkpoints
          checkpoints/*
          !checkpoints/.gitkeep
          *.pt
          *.pth
          *.ckpt
          
          # Experiments
          experiments/runs/
          
          # Environment
          .env
          .env.local
          
          # IDE
          .idea/
          .vscode/
          *.swp
          *.swo
          
          # OS
          .DS_Store
          Thumbs.db
          
          # Testing
          .pytest_cache/
          .coverage
          htmlcov/
          EOF
          
          cat > README.md << 'EOF'
          # ${{ inputs.project_name }}
          
          A PyTorch machine learning project.
          
          ## Tech Stack
          
          - Python: ${{ inputs.python_version }}
          - PyTorch: ${{ inputs.pytorch_version }}
          
          ## Quick Start
          
          ```bash
          # Create virtual environment
          python -m venv venv
          source venv/bin/activate  # On Windows: venv\Scripts\activate
          
          # Install dependencies
          pip install -r requirements.txt
          pip install -r requirements-dev.txt  # For development
          
          # Run training
          python train.py --epochs 10 --batch-size 32
          
          # Or with config file
          python train.py --config experiments/config.yaml
          
          # Monitor with TensorBoard
          tensorboard --logdir experiments/runs
          ```
          
          ## Project Structure
          
          ```
          ${{ inputs.project_name }}/
          ├── src/
          │   ├── models/          # Model definitions
          │   │   └── base.py
          │   ├── data/            # Data loading utilities
          │   │   └── dataset.py
          │   └── utils/           # Training utilities
          │       ├── trainer.py
          │       └── config.py
          ├── notebooks/           # Jupyter notebooks
          ├── experiments/         # Experiment configs and logs
          ├── data/
          │   ├── raw/            # Raw data
          │   └── processed/      # Processed data
          ├── checkpoints/        # Model checkpoints
          ├── train.py            # Main training script
          ├── requirements.txt
          └── README.md
          ```
          EOF

      - name: Create repo and push
        env:
          GH_TOKEN: ${{ secrets.PAT_TOKEN }}
        run: |
          cd ${{ inputs.project_name }}
          git config --global user.name "${{ github.actor }}"
          git config --global user.email "${{ github.actor }}@users.noreply.github.com"
          git init
          git add .
          git commit -m "Initial PyTorch ${{ inputs.pytorch_version }} ML project"
          gh repo create ${{ inputs.project_name }} --${{ inputs.repo_visibility }} --source . --push
          echo "✅ Done: https://github.com/${{ github.repository_owner }}/${{ inputs.project_name }}"

  # ============================================================
  # Jupyter Project
  # ============================================================
  create-jupyter:
    needs: validate
    if: inputs.project_type == 'jupyter'
    runs-on: ubuntu-latest
    steps:
      - name: Set up Python ${{ inputs.python_version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ inputs.python_version }}

      - name: Create Jupyter project
        run: |
          mkdir ${{ inputs.project_name }}
          cd ${{ inputs.project_name }}
          
          # Create project structure
          mkdir -p notebooks data/raw data/processed reports src
          
          cat > requirements.txt << 'EOF'
          jupyter>=1.0.0
          jupyterlab>=4.0.0
          notebook>=7.0.0
          ipykernel>=6.25.0
          numpy>=1.24.0
          pandas>=2.0.0
          matplotlib>=3.7.0
          seaborn>=0.12.0
          scikit-learn>=1.3.0
          plotly>=5.18.0
          openpyxl>=3.1.0
          python-dotenv>=1.0.0
          EOF
          
          cat > requirements-dev.txt << 'EOF'
          ruff>=0.3.0
          nbstripout>=0.6.0
          EOF
          
          cat > src/__init__.py << 'EOF'
          EOF
          
          cat > src/utils.py << 'EOF'
          """Common utilities for notebooks."""
          import pandas as pd
          import matplotlib.pyplot as plt
          import seaborn as sns
          from pathlib import Path
          
          # Project paths
          PROJECT_ROOT = Path(__file__).parent.parent
          DATA_RAW = PROJECT_ROOT / "data" / "raw"
          DATA_PROCESSED = PROJECT_ROOT / "data" / "processed"
          REPORTS = PROJECT_ROOT / "reports"
          
          
          def setup_plotting():
              """Setup matplotlib and seaborn defaults."""
              plt.style.use('seaborn-v0_8-whitegrid')
              sns.set_palette("husl")
              plt.rcParams['figure.figsize'] = (10, 6)
              plt.rcParams['figure.dpi'] = 100
          
          
          def load_data(filename: str, raw: bool = True) -> pd.DataFrame:
              """Load data from data directory."""
              data_dir = DATA_RAW if raw else DATA_PROCESSED
              filepath = data_dir / filename
              
              if filepath.suffix == '.csv':
                  return pd.read_csv(filepath)
              elif filepath.suffix in ['.xlsx', '.xls']:
                  return pd.read_excel(filepath)
              elif filepath.suffix == '.parquet':
                  return pd.read_parquet(filepath)
              else:
                  raise ValueError(f"Unsupported file format: {filepath.suffix}")
          
          
          def save_data(df: pd.DataFrame, filename: str, processed: bool = True) -> None:
              """Save data to data directory."""
              data_dir = DATA_PROCESSED if processed else DATA_RAW
              filepath = data_dir / filename
              
              if filepath.suffix == '.csv':
                  df.to_csv(filepath, index=False)
              elif filepath.suffix in ['.xlsx', '.xls']:
                  df.to_excel(filepath, index=False)
              elif filepath.suffix == '.parquet':
                  df.to_parquet(filepath, index=False)
              else:
                  raise ValueError(f"Unsupported file format: {filepath.suffix}")
          EOF
          
          # Create placeholder files
          touch data/raw/.gitkeep
          touch data/processed/.gitkeep
          touch reports/.gitkeep
          
          cat > notebooks/01_data_exploration.ipynb << 'EOF'
          {
           "cells": [
            {
             "cell_type": "markdown",
             "metadata": {},
             "source": [
              "# Data Exploration\n",
              "\n",
              "This notebook explores and analyzes the dataset."
             ]
            },
            {
             "cell_type": "code",
             "execution_count": null,
             "metadata": {},
             "outputs": [],
             "source": [
              "# Standard imports\n",
              "import sys\n",
              "sys.path.append('..')\n",
              "\n",
              "import numpy as np\n",
              "import pandas as pd\n",
              "import matplotlib.pyplot as plt\n",
              "import seaborn as sns\n",
              "\n",
              "from src.utils import setup_plotting, DATA_RAW, DATA_PROCESSED\n",
              "\n",
              "setup_plotting()\n",
              "\n",
              "print(f\"NumPy: {np.__version__}\")\n",
              "print(f\"Pandas: {pd.__version__}\")"
             ]
            },
            {
             "cell_type": "markdown",
             "metadata": {},
             "source": [
              "## Load Data"
             ]
            },
            {
             "cell_type": "code",
             "execution_count": null,
             "metadata": {},
             "outputs": [],
             "source": [
              "# Load your data here\n",
              "# df = pd.read_csv(DATA_RAW / 'your_data.csv')\n",
              "# df.head()"
             ]
            },
            {
             "cell_type": "markdown",
             "metadata": {},
             "source": [
              "## Data Overview"
             ]
            },
            {
             "cell_type": "code",
             "execution_count": null,
             "metadata": {},
             "outputs": [],
             "source": [
              "# Explore your data\n",
              "# df.info()\n",
              "# df.describe()"
             ]
            },
            {
             "cell_type": "markdown",
             "metadata": {},
             "source": [
              "## Visualizations"
             ]
            },
            {
             "cell_type": "code",
             "execution_count": null,
             "metadata": {},
             "outputs": [],
             "source": [
              "# Create visualizations\n",
              "# plt.figure(figsize=(10, 6))\n",
              "# sns.histplot(data=df, x='column_name')\n",
              "# plt.title('Distribution')\n",
              "# plt.show()"
             ]
            }
           ],
           "metadata": {
            "kernelspec": {
             "display_name": "Python 3",
             "language": "python",
             "name": "python3"
            },
            "language_info": {
             "name": "python",
             "version": "${{ inputs.python_version }}"
            }
           },
           "nbformat": 4,
           "nbformat_minor": 4
          }
          EOF
          
          cat > notebooks/02_data_cleaning.ipynb << 'EOF'
          {
           "cells": [
            {
             "cell_type": "markdown",
             "metadata": {},
             "source": [
              "# Data Cleaning\n",
              "\n",
              "This notebook handles data cleaning and preprocessing."
             ]
            },
            {
             "cell_type": "code",
             "execution_count": null,
             "metadata": {},
             "outputs": [],
             "source": [
              "import sys\n",
              "sys.path.append('..')\n",
              "\n",
              "import numpy as np\n",
              "import pandas as pd\n",
              "\n",
              "from src.utils import load_data, save_data, DATA_RAW, DATA_PROCESSED"
             ]
            },
            {
             "cell_type": "markdown",
             "metadata": {},
             "source": [
              "## Load Raw Data"
             ]
            },
            {
             "cell_type": "code",
             "execution_count": null,
             "metadata": {},
             "outputs": [],
             "source": [
              "# df = load_data('your_data.csv', raw=True)"
             ]
            },
            {
             "cell_type": "markdown",
             "metadata": {},
             "source": [
              "## Clean Data"
             ]
            },
            {
             "cell_type": "code",
             "execution_count": null,
             "metadata": {},
             "outputs": [],
             "source": [
              "# Handle missing values\n",
              "# Handle duplicates\n",
              "# Fix data types\n",
              "# etc."
             ]
            },
            {
             "cell_type": "markdown",
             "metadata": {},
             "source": [
              "## Save Processed Data"
             ]
            },
            {
             "cell_type": "code",
             "execution_count": null,
             "metadata": {},
             "outputs": [],
             "source": [
              "# save_data(df_cleaned, 'cleaned_data.csv', processed=True)"
             ]
            }
           ],
           "metadata": {
            "kernelspec": {
             "display_name": "Python 3",
             "language": "python",
             "name": "python3"
            },
            "language_info": {
             "name": "python",
             "version": "${{ inputs.python_version }}"
            }
           },
           "nbformat": 4,
           "nbformat_minor": 4
          }
          EOF
          
          cat > notebooks/03_analysis.ipynb << 'EOF'
          {
           "cells": [
            {
             "cell_type": "markdown",
             "metadata": {},
             "source": [
              "# Analysis\n",
              "\n",
              "Main analysis notebook."
             ]
            },
            {
             "cell_type": "code",
             "execution_count": null,
             "metadata": {},
             "outputs": [],
             "source": [
              "import sys\n",
              "sys.path.append('..')\n",
              "\n",
              "import numpy as np\n",
              "import pandas as pd\n",
              "import matplotlib.pyplot as plt\n",
              "import seaborn as sns\n",
              "from sklearn.model_selection import train_test_split\n",
              "\n",
              "from src.utils import setup_plotting, load_data\n",
              "\n",
              "setup_plotting()"
             ]
            },
            {
             "cell_type": "markdown",
             "metadata": {},
             "source": [
              "## Load Processed Data"
             ]
            },
            {
             "cell_type": "code",
             "execution_count": null,
             "metadata": {},
             "outputs": [],
             "source": [
              "# df = load_data('cleaned_data.csv', raw=False)"
             ]
            },
            {
             "cell_type": "markdown",
             "metadata": {},
             "source": [
              "## Analysis"
             ]
            },
            {
             "cell_type": "code",
             "execution_count": null,
             "metadata": {},
             "outputs": [],
             "source": [
              "# Your analysis here"
             ]
            }
           ],
           "metadata": {
            "kernelspec": {
             "display_name": "Python 3",
             "language": "python",
             "name": "python3"
            },
            "language_info": {
             "name": "python",
             "version": "${{ inputs.python_version }}"
            }
           },
           "nbformat": 4,
           "nbformat_minor": 4
          }
          EOF
          
          cat > .gitignore << 'EOF'
          # Python
          __pycache__/
          *.py[cod]
          *$py.class
          *.so
          .Python
          build/
          develop-eggs/
          dist/
          downloads/
          eggs/
          .eggs/
          lib/
          lib64/
          parts/
          sdist/
          var/
          wheels/
          *.egg-info/
          .installed.cfg
          *.egg
          
          # Virtual Environment
          venv/
          .venv/
          ENV/
          env/
          
          # Jupyter
          .ipynb_checkpoints/
          *.ipynb_checkpoints
          
          # Data - keep structure but ignore contents
          data/raw/*
          data/processed/*
          !data/raw/.gitkeep
          !data/processed/.gitkeep
          
          # Reports
          reports/*
          !reports/.gitkeep
          
          # Environment
          .env
          .env.local
          
          # IDE
          .idea/
          .vscode/
          *.swp
          *.swo
          
          # OS
          .DS_Store
          Thumbs.db
          EOF
          
          cat > README.md << 'EOF'
          # ${{ inputs.project_name }}
          
          A Jupyter data analysis project.
          
          ## Tech Stack
          
          - Python: ${{ inputs.python_version }}
          - Jupyter Lab
          
          ## Quick Start
          
          ```bash
          # Create virtual environment
          python -m venv venv
          source venv/bin/activate  # On Windows: venv\Scripts\activate
          
          # Install dependencies
          pip install -r requirements.txt
          pip install -r requirements-dev.txt  # For development
          
          # Start Jupyter Lab
          jupyter lab
          ```
          
          ## Project Structure
          
          ```
          ${{ inputs.project_name }}/
          ├── notebooks/
          │   ├── 01_data_exploration.ipynb
          │   ├── 02_data_cleaning.ipynb
          │   └── 03_analysis.ipynb
          ├── src/
          │   └── utils.py          # Common utilities
          ├── data/
          │   ├── raw/              # Original data
          │   └── processed/        # Cleaned data
          ├── reports/              # Generated reports
          ├── requirements.txt
          └── README.md
          ```
          
          ## Workflow
          
          1. Place raw data in `data/raw/`
          2. Run `01_data_exploration.ipynb` to understand the data
          3. Run `02_data_cleaning.ipynb` to clean and preprocess
          4. Run `03_analysis.ipynb` for analysis
          5. Export reports to `reports/`
          EOF

      - name: Create repo and push
        env:
          GH_TOKEN: ${{ secrets.PAT_TOKEN }}
        run: |
          cd ${{ inputs.project_name }}
          git config --global user.name "${{ github.actor }}"
          git config --global user.email "${{ github.actor }}@users.noreply.github.com"
          git init
          git add .
          git commit -m "Initial Jupyter data analysis project"
          gh repo create ${{ inputs.project_name }} --${{ inputs.repo_visibility }} --source . --push
          echo "✅ Done: https://github.com/${{ github.repository_owner }}/${{ inputs.project_name }}"

  # ============================================================
  # React Project (Vite)
  # ============================================================
  create-react:
    needs: validate
    if: inputs.project_type == 'react'
    runs-on: ubuntu-latest
    steps:
      - name: Set up Node.js ${{ inputs.node_version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ inputs.node_version }}

      - name: Create React project
        run: |
          npm create vite@latest ${{ inputs.project_name }} -- --template react-ts
          cd ${{ inputs.project_name }}
          
          # Update package.json with React version
          npm pkg set dependencies.react="^${{ inputs.react_version }}.0.0"
          npm pkg set dependencies.react-dom="^${{ inputs.react_version }}.0.0"
          
          # Install dependencies
          npm install
          
          # Add commonly used dev dependencies
          npm install -D @types/node
          
          # Update .gitignore
          cat > .gitignore << 'EOF'
          # Dependencies
          node_modules/
          
          # Build
          dist/
          dist-ssr/
          build/
          
          # Environment
          .env
          .env.local
          .env.*.local
          
          # Logs
          logs/
          *.log
          npm-debug.log*
          yarn-debug.log*
          yarn-error.log*
          pnpm-debug.log*
          lerna-debug.log*
          
          # IDE
          .idea/
          .vscode/*
          !.vscode/extensions.json
          *.suo
          *.ntvs*
          *.njsproj
          *.sln
          *.sw?
          
          # OS
          .DS_Store
          Thumbs.db
          
          # Testing
          coverage/
          
          # Misc
          *.local
          EOF
          
          # Create .env.example
          cat > .env.example << 'EOF'
          VITE_API_URL=http://localhost:3000
          EOF
          
          # Update README
          cat > README.md << 'EOF'
          # ${{ inputs.project_name }}
          
          A React project built with Vite.
          
          ## Tech Stack
          
          - Node.js: ${{ inputs.node_version }}
          - React: ${{ inputs.react_version }}
          - TypeScript
          - Vite
          
          ## Quick Start
          
          ```bash
          # Install dependencies
          npm install
          
          # Start development server
          npm run dev
          
          # Build for production
          npm run build
          
          # Preview production build
          npm run preview
          ```
          
          ## Project Structure
          
          ```
          ${{ inputs.project_name }}/
          ├── public/
          ├── src/
          │   ├── assets/
          │   ├── App.tsx
          │   ├── App.css
          │   ├── main.tsx
          │   └── index.css
          ├── index.html
          ├── package.json
          ├── tsconfig.json
          ├── vite.config.ts
          └── README.md
          ```
          
          ## Available Scripts
          
          - `npm run dev` - Start development server
          - `npm run build` - Build for production
          - `npm run preview` - Preview production build
          - `npm run lint` - Run ESLint
          EOF

      - name: Create repo and push
        env:
          GH_TOKEN: ${{ secrets.PAT_TOKEN }}
        run: |
          cd ${{ inputs.project_name }}
          git config --global user.name "${{ github.actor }}"
          git config --global user.email "${{ github.actor }}@users.noreply.github.com"
          
          # Remove default git if exists and reinit
          rm -rf .git
          git init
          git add .
          git commit -m "Initial React ${{ inputs.react_version }} + Vite project"
          gh repo create ${{ inputs.project_name }} --${{ inputs.repo_visibility }} --source . --push
          echo "✅ Done: https://github.com/${{ github.repository_owner }}/${{ inputs.project_name }}"

  # ============================================================
  # Vue Project (Vite)
  # ============================================================
  create-vue:
    needs: validate
    if: inputs.project_type == 'vue'
    runs-on: ubuntu-latest
    steps:
      - name: Set up Node.js ${{ inputs.node_version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ inputs.node_version }}

      - name: Create Vue project
        run: |
          npm create vite@latest ${{ inputs.project_name }} -- --template vue-ts
          cd ${{ inputs.project_name }}
          
          # Update package.json with Vue version
          npm pkg set dependencies.vue="^${{ inputs.vue_version }}.0"
          
          # Install dependencies
          npm install
          
          # Add commonly used dev dependencies
          npm install -D @types/node
          
          # Update .gitignore
          cat > .gitignore << 'EOF'
          # Dependencies
          node_modules/
          
          # Build
          dist/
          dist-ssr/
          build/
          
          # Environment
          .env
          .env.local
          .env.*.local
          
          # Logs
          logs/
          *.log
          npm-debug.log*
          yarn-debug.log*
          yarn-error.log*
          pnpm-debug.log*
          lerna-debug.log*
          
          # IDE
          .idea/
          .vscode/*
          !.vscode/extensions.json
          *.suo
          *.ntvs*
          *.njsproj
          *.sln
          *.sw?
          
          # OS
          .DS_Store
          Thumbs.db
          
          # Testing
          coverage/
          
          # Misc
          *.local
          EOF
          
          # Create .env.example
          cat > .env.example << 'EOF'
          VITE_API_URL=http://localhost:3000
          EOF
          
          # Update README
          cat > README.md << 'EOF'
          # ${{ inputs.project_name }}
          
          A Vue project built with Vite.
          
          ## Tech Stack
          
          - Node.js: ${{ inputs.node_version }}
          - Vue: ${{ inputs.vue_version }}
          - TypeScript
          - Vite
          
          ## Quick Start
          
          ```bash
          # Install dependencies
          npm install
          
          # Start development server
          npm run dev
          
          # Build for production
          npm run build
          
          # Preview production build
          npm run preview
          ```
          
          ## Project Structure
          
          ```
          ${{ inputs.project_name }}/
          ├── public/
          ├── src/
          │   ├── assets/
          │   ├── components/
          │   │   └── HelloWorld.vue
          │   ├── App.vue
          │   ├── main.ts
          │   └── style.css
          ├── index.html
          ├── package.json
          ├── tsconfig.json
          ├── vite.config.ts
          └── README.md
          ```
          
          ## Available Scripts
          
          - `npm run dev` - Start development server
          - `npm run build` - Build for production
          - `npm run preview` - Preview production build
          - `npm run lint` - Run ESLint (if configured)
          EOF

      - name: Create repo and push
        env:
          GH_TOKEN: ${{ secrets.PAT_TOKEN }}
        run: |
          cd ${{ inputs.project_name }}
          git config --global user.name "${{ github.actor }}"
          git config --global user.email "${{ github.actor }}@users.noreply.github.com"
          
          # Remove default git if exists and reinit
          rm -rf .git
          git init
          git add .
          git commit -m "Initial Vue ${{ inputs.vue_version }} + Vite project"
          gh repo create ${{ inputs.project_name }} --${{ inputs.repo_visibility }} --source . --push
          echo "✅ Done: https://github.com/${{ github.repository_owner }}/${{ inputs.project_name }}"